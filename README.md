# Detection of Large-Language Model (LLM) Generated Text ğŸ“ğŸ¤–

[<img src="https://img.icons8.com/material-outlined/24/000000/github.png" width="24" height="24"/>](https://github.com/Harshithvarma007/LLM_Text_Detection)
[<img src="https://www.cdnlogo.com/logos/k/70/kaggle.svg" width="24" height="24"/>](https://www.kaggle.com/code/harshithvarma007/llm-text-detection-99-47-accuracy)
[<img src="https://img.icons8.com/ios-filled/24/000000/medium-monogram.png" width="24" height="24"/>](https://medium.com/@harshith007varma007/llm-text-detection-79aa048fd325)
[<img src="https://img.icons8.com/ios-filled/24/000000/link.png" width="24" height="24"/>](http://54.196.76.117:8501/)





## ğŸŒŸ Introduction

Welcome to the **Detection of Large-Language Model (LLM) Generated Text** project! This project aims to distinguish between human-generated and LLM-generated text, addressing concerns related to misinformation, plagiarism, and ethics. With the rise of LLM models like GPT-4, it has become crucial to develop robust detection mechanisms to ensure the integrity and reliability of text-based communication.

## ğŸ“š Project Overview

### ğŸ” Need for Detection of LLM Generated Text
The need for detecting LLM-generated text arises from several factors:
- **Misinformation Control:** ğŸš« LLMs can spread false information rapidly. Detection helps in identifying and mitigating the impact of misinformation.
- **Plagiarism Prevention:** ğŸ“ Identifying LLM-generated content assists in preventing academic and content plagiarism, maintaining integrity in research and publications.
- **Ethical Considerations:** âš–ï¸ Understanding the origin of text content is crucial for maintaining ethical standards, especially in sensitive areas like news reporting and legal documentation.
- **Trust and Transparency:** ğŸ” Detection fosters trust by ensuring transparency about the source of text content, enhancing credibility in communication channels.

### âš™ï¸ Methodology
In this project, we leverage natural language processing (NLP) techniques to build an effective detection system. The process includes:
1. **Data Collection:** Gathering a diverse dataset of human and LLM-generated texts.
2. **Feature Engineering:** Extracting relevant features that can distinguish between human and LLM-generated texts.
3. **Model Selection:** Choosing appropriate machine learning models for classification.
4. **Evaluation:** Assessing model performance using metrics like accuracy, precision, recall, and F1-score.

### ğŸš€ Project Deployment
The project has been successfully deployed! Check it out here:
[![Deployed Project](https://img.icons8.com/ios-filled/24/000000/link.png)](http://54.196.76.117:8501/)

### ğŸ“Š Project Notebook
Explore the detailed project notebook on Kaggle:
[![Kaggle](https://img.icons8.com/ios-filled/24/000000/kaggle.png)](https://www.kaggle.com/code/harshithvarma007/llm-text-detection-99-47-accuracy)

### ğŸ“– Read the Blog
Dive into the full story behind this project on Medium:
[![Medium](https://img.icons8.com/ios-filled/24/000000/medium-monogram.png)](https://medium.com/@harshith007varma007/llm-text-detection-79aa048fd325)

## ğŸ› ï¸ Setup and Installation

Follow these steps to set up and run the project locally:

1. **Clone the repository:**
    ```sh
    git clone -b Deployment https://github.com/Harshithvarma007/LLM_Text_Detection.git
    cd LLM_Text_Detection
    ```

2. **Set up virtual environment and install dependencies:**
    ```sh
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

3. **Run the Streamlit app:**
    ```sh
    streamlit run app.py
    ```
Follow the below steps to train the model Locally:

Certainly! Here are the steps formatted in a more readable and presentable way:

---

## ğŸš€ Training the Model Locally

To train the model locally, follow these steps:

### Step 1: Clone the Repository

```sh
git clone -b main https://github.com/Harshithvarma007/LLM_Text_Detection.git
cd LLM_Text_Detection
```

### Step 2: Set Up Virtual Environment and Install Dependencies

```sh
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```


This script will train the detection model using the configured dataset and save the trained model weights.

### Step 3: Run the Application

Start the Streamlit app to interact with the trained model:

```sh
streamlit run app.py
```

### Step 4: Navigate the App

Once the Streamlit app is running, open your web browser and visit [http://localhost:8501](http://localhost:8501). Navigate within the app to find the "Train Model" button to initiate training if it's not already trained using `train.py`.


## ğŸ¤ Contributing

We welcome contributions! Please feel free to submit issues, fork the repository, and send pull requests.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“¬ Contact

Feel free to reach out for any queries or collaboration opportunities!

**Harshith Varma**
- [GitHub](https://github.com/Harshithvarma007)
- [LinkedIn](https://www.linkedin.com/in/harshith-varma-668a7a23b/)
- [Medium](https://medium.com/@harshith007varma007)

---

Thank you for checking out this project! ğŸ™Œ We hope you find it useful and informative. Happy coding! ğŸ’»ğŸ‰
